---
title: 潛在的狄氏配置：模組參考
titleSuffix: Azure Machine Learning
description: 瞭解如何使用潛在的狄氏配置模組，將其他未分類的文字分組為類別目錄。
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: reference
author: likebupt
ms.author: keli19
ms.date: 06/05/2020
ms.openlocfilehash: 2fa969b6dd89000b4d669bc5d42aa09b3cf3a2b2
ms.sourcegitcommit: 877491bd46921c11dd478bd25fc718ceee2dcc08
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 07/02/2020
ms.locfileid: "84751686"
---
# <a name="latent-dirichlet-allocation-module"></a>潛在的狄氏配置模組

本文說明如何使用 Azure Machine Learning 設計工具（預覽）中的潛在狄氏配置模組，將其他未分類的文字分組為類別目錄。 

潛在的狄氏配置（LDA）通常用於自然語言處理，以尋找類似的文字。 另一個常見的詞彙是*主題模型*化。

此模組會使用文字資料行並產生下列輸出：

+ 來源文字，以及每個類別的分數

+ 包含每個類別之已解壓縮詞彙和係數的功能矩陣

+ 轉換，您可以儲存並重新套用至做為輸入使用的新文字

此課程模組使用 scikit-learn-瞭解程式庫。 如需 scikit-learn 的詳細資訊，請參閱 [GitHub 存放庫](https://github.com/scikit-learn/scikit-learn)，其中包含有關演算法的教學課程和說明。

## <a name="more-about-latent-dirichlet-allocation"></a>進一步瞭解潛在的狄氏配置

LDA 通常不是分類的方法。 但它會使用有生產力方法，因此您不需要提供已知的類別標籤，然後推斷模式。  相反地，此演算法會產生用來識別主題群組的概率模型。 您可以使用概率模型，將您提供給模型的現有定型案例或新案例分類為輸入。

您可能偏好使用有生產力模型，因為它可避免對文字和類別之間的關聯性做出強烈的假設。 它只會使用單字的分佈，以數學方式建立主題的模型。

本檔中討論的理論是以 PDF 下載的形式提供：[潛在的狄氏配置： Blei、Ng 和約旦](https://ai.stanford.edu/~ang/papers/nips01-lda.pdf)。

此課程模組中的實作為基礎，適用于 LDA 的[scikit-learn 學習程式庫](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/decomposition/_lda.py)。

如需詳細資訊，請參閱[技術](#technical-notes)提示一節。

## <a name="how-to-configure-latent-dirichlet-allocation"></a>如何設定潛在的狄氏配置

此模組需要一個資料集，其中包含未經處理或前置處理的文字資料行。

1. 將**潛在的狄氏配置**模組新增至您的管線。

2. 作為模組的輸入，提供包含一或多個文字資料行的資料集。

3. 針對 [**目標資料行**]，選擇包含要分析之文字的一或多個資料行。

    您可以選擇多個資料行，但它們必須是**字串**資料類型。

    因為 LDA 會從文字建立大型特徵矩陣，所以您通常會分析單一文字資料行。

4. 針對 [**要建立模型的主題數目**]，輸入介於1到1000之間的整數，表示您想要從輸入文字中衍生多少類別或主題。

    預設會建立5個主題。

5. 針對**n**個字母，請指定在雜湊期間產生的 n 字母長度上限。

    預設值為2，表示會同時產生 bigrams 和 unigrams。

6. 選取 [**正規化] 選項，將**輸出值轉換為 [機率]。 

    輸出和功能資料集中的值，不會以整數表示轉換後的值，而是以下列方式轉換：

    + 資料集中的值將會表示為的機率 `P(topic|document)` 。

    + 功能主題矩陣中的值將會表示為的機率 `P(word|topic)` 。

    > [!NOTE] 
    > 在 Azure Machine Learning 設計工具（預覽）中，scikit-learn 學習程式庫不再支援0.19 版的未標準化*doc_topic_distr*輸出。 在此課程模組中 **，正規化參數只能**套用至*功能主題矩陣*輸出。 *轉換的資料集*輸出一律是正規化的。

7. 選取 [**顯示所有選項**] 選項，如果您想要設定下列 advanced 參數，請將它設定為 [ **TRUE** ]。

    這些參數是 LDA 的 scikit-learn 學習執行特有的。 Scikit-learn 中的 LDA 有一些不錯的教學課程，以及官方的[scikit-learn-學習檔](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html)。

    + **Rho 參數**。 提供主題散發之稀疏性的先前機率。 這個參數會對應至 sklearn 的 `topic_word_prior` 參數。 如果您預期單字的分佈是平面的，請使用值**1** 。也就是說，所有單字都會假設為 equiprobable。 如果您認為大部分的文字都是稀疏出現，您可能會將它設定為較低的值。

    + **Alpha 參數**。 針對每個檔主題加權的稀疏性指定先前的機率。 這個參數會對應至 sklearn 的 `doc_topic_prior` 參數。

    + **估計的檔數目**。 輸入數位，代表要處理的檔（資料列）數目的最佳估計。 此參數可讓模組配置足夠大小的雜湊表。 它會對應到 `total_samples` scikit-learn 中的參數。

    + **批次的大小**。 輸入一個數位，指出要在傳送至 LDA 模型的每個文字批次中包含多少個數據列。 此參數會對應至 `batch_size` scikit-learn 中的參數。

    + **用於學習更新排程的反復專案初始值**。 指定開始值，在線上學習中 downweights 早期反覆運算的學習速率。 此參數會對應至 `learning_offset` scikit-learn 中的參數。

    + **更新期間套用至反復專案的電源**。 指出套用到反復專案計數的功率層級，以便在線上更新期間控制學習速率。 此參數會對應至 `learning_decay` scikit-learn 中的參數。

    + **資料的傳遞數目**。 指定演算法將在資料上迴圈的次數上限。 此參數會對應至 `max_iter` scikit-learn 中的參數。

8. 如果您想要在分類文字之前的初始階段中建立 n 語法清單，請選取 [LDA 前的**ngrams**或**建立 ngrams 的組建**字典] 選項。

    如果您事先建立初始字典，您稍後可以在檢查模型時使用字典。 能夠將結果對應至文字，而不是數值索引，通常比較容易用於轉譯。 不過，儲存字典將會花費較長的時間，並使用額外的儲存空間。

9. 在 [ **ngram 字典的大小上限**] 中，輸入可在 n #-克字典中建立的資料列總數。

    此選項適用于控制字典的大小。 但是，如果輸入中的 ngrams 數目超過此大小，可能會發生衝突。

10. 提交管線。 LDA 模組會使用貝氏機率分類定理來判斷哪些主題可能與個別單字相關聯。 單字不會以獨佔方式與任何主題或群組相關聯。 相反地，每個 n-克都具有與任何探索到的類別相關聯的已學習機率。

## <a name="results"></a>結果

此模組有兩個輸出：

+ 已**轉換的資料集**：此輸出包含輸入文字、所找到的指定數目的類別，以及每個類別的每個文字範例分數。

+ **功能主題矩陣**：最左邊的資料行包含已解壓縮的文字功能。 每個類別的資料行都包含該類別中該功能的分數。


### <a name="lda-transformation"></a>LDA 轉換

此模組也會輸出將 LDA 套用至資料集的*LDA 轉換*。

您可以儲存此轉換，並將它重複用於其他資料集。 如果您已在大型主體上定型，而且想要重複使用係數或類別，這項技術可能會很有用。

若要重複使用此轉換，請選取 [潛在狄氏配置] 模組右面板中的 [**註冊資料集**] 圖示，以將模組保留在模組清單中的 [**資料集**] 類別之下。 接著，您可以將此模組連接到 [套用[轉換](apply-transformation.md)] 模組，以重複使用此轉換。

### <a name="refining-an-lda-model-or-results"></a>精簡 LDA 模型或結果

一般來說，您無法建立可符合所有需求的單一 LDA 模型。 即使是針對一個工作所設計的模型，也可能需要多個反復專案來改善精確度。 我們建議您嘗試所有這些方法來改善您的模型：

+ 變更模型參數
+ 使用視覺效果來瞭解結果
+ 取得主題專家的意見反應，以判斷產生的主題是否有用

定性量值也有助於評估結果。 若要評估主題模型化結果，請考慮：

+ 精確度。 類似的專案真的很相似嗎？
+ 變化. 當商務問題需要時，模型是否可以區分相似的專案？
+ 延展性。 它是否適用于各式各樣的文字分類，或只能在較窄的目標網域上運作？

您通常可以使用自然語言處理來清除、摘要和簡化或分類文字，以根據 LDA 來改善模型的精確度。 例如，在 Azure Machine Learning 中支援的下列技術可以改善分類精確度：

+ 停用字詞移除

+ 大小寫正規化

+ 詞形歸併還原或詞幹分析

+ 具名實體辨識

如需詳細資訊，請參閱前置處理[文字](preprocess-text.md)。

在設計工具中，您也可以使用 R 或 Python 程式庫來處理文字：[執行 r 腳本](execute-r-script.md)、[執行 Python 腳本](execute-python-script.md)。



## <a name="technical-notes"></a>技術說明

本章節包含執行詳細資料、秘訣和常見問題的解答。

### <a name="implementation-details"></a>實作詳細資料

根據預設，已轉換資料集和功能主題矩陣的輸出分佈會正規化為機率：

+ 已轉換的資料集會正規化為給定檔之主題的條件機率。 在此情況下，每個資料列的總和等於1。

+ 功能主題矩陣會正規化為指定主題之單字的條件機率。 在此情況下，每個資料行的總和等於1。

> [!TIP]
> 模組有時可能會傳回空白的主題。 最常見的原因是演算法的虛擬隨機初始化。 如果發生這種情況，您可以嘗試變更相關的參數。 例如，變更 N 語法字典的大小上限或要用於特徵雜湊的位數。

### <a name="lda-and-topic-modeling"></a>LDA 和主題模型化

潛在的狄氏配置通常用於以*內容為基礎的主題模型*化，這基本上表示從未分類的文字學習分類。 在以內容為基礎的主題模型中，主題是一種透過單字的散發。

例如，假設您已提供客戶評論的主體，其中包含許多產品。 客戶在一段時間內提交的評論文字包含許多詞彙，其中有些是用於多個主題。

LDA 流程識別的*主題*可能代表個別產品的評論，或可能代表一組產品評論。 若要 LDA，主題本身只是一組單字的一段時間的機率分佈。

對於任何一項產品而言，詞彙並不是互斥的。 它們可以參考其他產品，或是適用于所有專案（「絕佳」、「極佳」）的一般詞彙。 其他詞彙則可能是非搜尋字。 不過，LDA 方法不會嘗試捕獲 universe 中的所有單字，或除了共同發生的機率之外，也不會瞭解文字的關聯方式。 它只能將目標網域中使用的單字群組在一起。

計算詞彙索引之後，以距離為基礎的相似性量值會比較個別的文字資料列，以判斷兩段文字是否類似。 例如，您可能會發現產品有多個強相互關聯的名稱。 或者，您可能會發現，強烈的負詞彙通常與特定的產品相關聯。 您可以使用 [相似性] 量值來識別相關詞彙，並建立建議。

###  <a name="module-parameters"></a>模組參數

|名稱|類型|範圍|選擇性|預設|描述|  
|----------|----------|-----------|--------------|-------------|-----------------|  
|目標資料行|資料行選取||必要|StringFeature|目標資料行名稱或索引。|  
|要建立模型的主題數目|整數|[1; 1000]|必要|5|針對 N 個主題建立檔散發模型。|  
|N 字母組|整數|[1; 10]|必要|2|雜湊期間產生的 N 字母順序。|  
|規範|Boolean|True 或 False|必要|true|將輸出正規化為機率。  轉換的資料集將會是 P （主題&#124;檔），而功能主題矩陣會是 P （word&#124;主題）。|  
|顯示所有選項|Boolean|True 或 False|必要|False|提供 scikit-learn 專用的其他參數-瞭解線上 LDA。|  
|Rho 參數|Float|[0.00001; 1.0]|適用于選取 [**顯示所有選項**] 核取方塊時|0.01|主題 word 先前的散發。|  
|Alpha 參數|Float|[0.00001; 1.0]|適用于選取 [**顯示所有選項**] 核取方塊時|0.01|發行前的檔主題。|  
|估計的檔數目|整數|[1;int.MaxValue]|適用于選取 [**顯示所有選項**] 核取方塊時|1000|估計的檔數目。 對應至 `total_samples` 參數。|  
|批次的大小|整數|[1; 1024]|適用于選取 [**顯示所有選項**] 核取方塊時|32|批次的大小。|  
|學習速率更新排程中所用反復專案的初始值|整數|[0; int。MaxValue|適用于選取 [**顯示所有選項**] 核取方塊時|0|Downweights 早期反覆運算學習速率的初始值。 對應至 `learning_offset` 參數。|  
|更新期間套用至反復專案的電源|Float|[0.0; 1.0]|適用于選取 [**顯示所有選項**] 核取方塊時|0.5|已套用至反復專案計數的電源，以控制學習速率。 對應至 `learning_decay` 參數。 |  
|反覆定型的次數|整數|[1; 1024]|適用于選取 [**顯示所有選項**] 核取方塊時|25|定型反復專案的數目。|  
|Ngrams 的組建字典|Boolean|True 或 False|當*未*選取 [**顯示所有選項**] 核取方塊時套用|True|在計算 LDA 之前建立 ngrams 的字典。 適用于模型檢查和轉譯。|  
|Ngram 字典的大小上限|整數|[1;int.MaxValue]|適用于 ngrams 的選項**建立字典**為**True**時|20000|Ngrams 字典的大小上限。 如果輸入中的權杖數目超過此大小，可能會發生衝突。|  
|要用於特徵雜湊的位數。|整數|[1; 31]|當*未*選取 [**顯示所有選項**] 核取方塊，且**Ngrams 的組建字典**為**False**時套用|12|要用於特徵雜湊的位數。| 
|LDA 之前的 ngrams 組建字典|Boolean|True 或 False|適用于選取 [**顯示所有選項**] 核取方塊時|True|在 LDA 之前建立 ngrams 的字典。 適用于模型檢查和轉譯。|  
|字典中的 ngrams 數目上限|整數|[1;int.MaxValue]|適用于已選取 [**顯示所有選項**] 核取方塊，且**Ngrams 的 [建立字典**] 選項為**True**時|20000|字典的大小上限。 如果輸入中的權杖數目超過此大小，可能會發生衝突。|  
|雜湊位數目|整數|[1; 31]|適用于已選取 [**顯示所有選項**] 核取方塊，且 [ngrams] 選項的 [**建立字典**] 為**False**時|12|功能雜湊期間要使用的位數。|   


## <a name="next-steps"></a>後續步驟

請參閱 Azure Machine Learning 的[可用模組集](module-reference.md)。 

如需模組特有的錯誤清單，請參閱設計工具的[例外狀況和錯誤碼](designer-error-codes.md)。
