---
title: 評估模型：模組參考
titleSuffix: Azure Machine Learning
description: 瞭解如何在 Azure 機器學習中使用評估模型模組來測量經過培訓的模型的準確性。
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: reference
author: likebupt
ms.author: keli19
ms.date: 02/24/2020
ms.openlocfilehash: c1bcbb6a368c9c80f968c48c1a6e0bc6c95133d6
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 03/28/2020
ms.locfileid: "79456399"
---
# <a name="evaluate-model-module"></a>評估模型模組

本文介紹 Azure 機器學習設計器（預覽）中的模組。

使用此模組測量經過訓練的模型的準確性。 提供包含從模型生成的分數的資料集，評估**模型**模組計算一組行業標準評估指標。
  
 **評估模型**返回的指標取決於要評估的模型類型：  
  
-   **分類模型**    
-   **回歸模型**  
-   **聚類模型**  


> [!TIP]
> 如果您是模型評估的新產品，我們建議您使用 Stephen Elston 博士的視頻系列，作為 EdX[機器學習課程](https://blogs.technet.microsoft.com/machinelearning/2015/09/08/new-edx-course-data-science-machine-learning-essentials/)的一部分。 


有三種使用**評估模型**模組的方法：

+ 生成培訓資料的分數，並根據這些分數評估模型
+ 生成模型上的分數，但將這些分數與保留測試集上的分數進行比較
+ 使用同一組資料比較兩個不同但相關的模型的分數

## <a name="use-the-training-data"></a>使用培訓資料

若要評估模型，您必須連接包含一組輸入資料行和分數的資料集。  如果沒有其他資料可用，則可以使用原始資料集。

1. 將[分數模型](./score-model.md)的**評分資料集**輸出連接到**評估模型**的輸入。 
2. 按一下 **"評估模型"** 模組，然後運行管道以生成評估分數。

## <a name="use-testing-data"></a>使用測試資料

機器學習中的一個常見方案是使用[拆分](./split-data.md)模組或[分區和示例](./partition-and-sample.md)模組將原始資料集分離到訓練資料集和測試資料集中。 

1. 將[分數模型](score-model.md)的**評分資料集**輸出連接到**評估模型**的輸入。 
2. 將包含測試資料的拆分資料模組的輸出連接到**評估模型**的右側輸入。
2. 按一下 **"評估模型"** 模組，然後選擇 **"運行"** 以生成評估分數。

## <a name="compare-scores-from-two-models"></a>比較兩個模型的分數

您還可以將第二組分數連接到**評估模型**。  分數可能是具有已知結果的共用評估集，也可以是同一資料的不同模型的結果集。

這項功能很有用，因為您可以輕鬆地比較兩個不同的模型使用相同資料的結果。 或者，您可以比較兩個不同的回合使用相同資料、不同參數的分數。

1. 將[分數模型](score-model.md)的**評分資料集**輸出連接到**評估模型**的輸入。 
2. 將第二個模型的分數模型模組的輸出連接到**評估模型**的右側輸入。
3. 提交管道。

## <a name="results"></a>結果

運行**評估模型**後，按右鍵模組並選擇**視覺化評估結果**以查看結果。

如果將資料集連接到**評估模型**的兩個輸入，則結果將包含兩組資料集或兩個模型的指標。
附加到左埠的模型或資料首先在報表中顯示，然後是資料集的指標或右側埠上附加的模型。  

例如，下圖表示基於相同資料構建但參數不同的兩個聚類模型的結果的比較。  

![比較2模型](media/module/evaluate-2-models.png)  

由於這是一個聚類模型，因此評估結果與比較兩個回歸模型的分數或比較兩個分類模型的分數不同。 但是，總體演示文稿是相同的。 

## <a name="metrics"></a>計量

本節介紹為支援與**評估模型**一起使用的特定類型的模型返回的指標：

+ [分類模型](#metrics-for-classification-models)
+ [回歸模型](#metrics-for-regression-models)
+ [聚類模型](#metrics-for-clustering-models)

### <a name="metrics-for-classification-models"></a>分類模型的指標

在評估分類模型時報告以下指標。
  
-   **精度**衡量分類模型的優劣，作為真實結果與總案例的比例。  
  
-   **精度**是真實結果與所有積極結果的比例。  
  
-   **撤回**是模型返回的所有正確結果的分數。  
  
-   **F 得分**計算為精度和召回的加權平均值 0 和 1 之間，其中理想的 F 得分值為 1。  
  
-   **AUC**測量曲線下繪製的面積，在 y 軸上繪製了真正的正數，X 軸上為誤報。 此指標很有用，因為它提供了一個數位，允許您比較不同類型的模型。  
  
- **平均日誌損失**是用於表示錯誤結果的懲罰的單一分數。 它計算為兩個概率分佈之間的差異 - 真正的和模型中的。  
  
- **訓練日誌丟失**是表示分類器比隨機預測的優勢的單一分數。 日誌損耗通過將模型輸出的概率與標籤中的已知值（地面真相）進行比較來測量模型的不確定性。 您希望將整個模型的日誌丟失降至最低。

### <a name="metrics-for-regression-models"></a>回歸模型的指標
 
為回歸模型返回的指標旨在估計誤差量。  如果觀測值和預測值之間的差異較小，則模型被視為非常適合資料。 但是，查看殘差的形態（任何預測點與其相應的實際值之間的差異）可以告訴您模型中的潛在偏差。  
  
 報告以下指標以評估回歸模型。
  
- **平均絕對誤差 （MAE）** 衡量預測與實際結果的接近程度;因此，分數越低越好。  
  
- **根均方誤差 （RMSE）** 創建一個值，以匯總模型中的錯誤。 通過計算差異，該指標忽略了過度預測和預測不足之間的區別。  
  
- **相對絕對誤差 （RAE）** 是預期值和實際值之間的相對絕對差;相對，因為平均差除以算術平均值。  
  
- **相對平方誤差 （RSE）** 同樣通過除以實際值的總平方誤差來正常化預測值的總平方誤差。  
  

  
- **確定係數**（通常稱為 R<sup>2）</sup>表示模型的預測能力，即介於 0 和 1 之間的值。 零表示模型是隨機的（解釋不一樣）;1 表示有一個完美的適合。 但是，在解釋 R<sup>2</sup>值時應小心謹慎，因為低值可能完全正常，並且可能懷疑高值。

###  <a name="metrics-for-clustering-models"></a>聚類模型的指標

由於聚類模型在許多方面與分類和回歸模型存在顯著差異，[因此評估模型](evaluate-model.md)還會為聚類模型返回一組不同的統計資訊。  
  
 為聚類模型返回的統計資訊描述分配給每個群集的資料點數、群集之間的分離量以及資料點在每個群集中的聚束緊密程度。  
  
 聚類模型的統計資訊在整個資料集上求平均值，其他行包含每個群集的統計資訊。  
  
報告以下指標用於評估聚類模型。
    
-   列中的分數"**與其他中心的平均距離**"表示群集中每個點的平均值與所有其他群集的質心的距離。   

-   列中的分數"**與群集中心的平均距離**"表示群集中所有點的接近于該群集的質心。  
  
-   "**點數"** 列顯示分配給每個群集的資料點數，以及任何群集中資料點的總數量。  
  
     如果分配給群集的資料點數小於可用資料點總數，則意味著無法將資料點分配給群集。  
  
-   列中的分數"**最大距離到聚類中心**"表示每個點與該點聚類的質心之間的距離之和。  
  
     如果此數位較高，則可能意味著群集分佈廣泛。 您應該查看此統計資訊以及**群集中心的平均距離**，以確定群集的分佈。   

-   結果各部分底部**的綜合評估**分數列出了該特定模型中創建的群集的平均分數。  
  

## <a name="next-steps"></a>後續步驟

請參閱 Azure 機器學習[可用的模組集](module-reference.md)。 