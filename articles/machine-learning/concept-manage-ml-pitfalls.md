---
title: 使用 AutoML 避免過度學習及不平衡資料
titleSuffix: Azure Machine Learning
description: 使用 Azure Machine Learning 的自動化機器學習解決方案來識別及管理 ML 模型的常見錯誤。
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: conceptual
ms.reviewer: nibaccam
author: nibaccam
ms.author: nibaccam
ms.date: 04/09/2020
ms.openlocfilehash: 77b5b52153c552008406b4b85083bcba5542cebe
ms.sourcegitcommit: 829d951d5c90442a38012daaf77e86046018e5b9
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 10/09/2020
ms.locfileid: "87012717"
---
# <a name="prevent-overfitting-and-imbalanced-data-with-automated-machine-learning"></a>使用自動化機器學習來防止過度學習與不平衡資料

當建置機器學習模型時，過度學習與不平衡資料是常見的錯誤。 根據預設，Azure Machine Learning 的自動化機器學習可提供圖表與計量，以協助找出這些風險，並實作最佳做法以協助降低這些風險。 

## <a name="identify-over-fitting"></a>識別過度學習

機器學習中的過度學習會在模型與定型資料相符程度太過完美時發生，導致無法正確預測隱形測試資料。 換句話說，此模型只是記下定型資料中的特定模式和失真，但是沒有足夠的彈性可對實際資料進行預測。

請注意下列已定型模型及其對應的定型和測試正確性。

| 模型 | 定型正確性 | 測試正確性 |
|-------|----------------|---------------|
| A | 99.9% | 95% |
| B | 87% | 87% |
| C | 99.9% | 45% |

對於模型 **A**，存在一個普遍的誤解，即認為如果對隱形資料的測試正確性低於定型正確性，則代表該模型過度學習。 實際上，測試正確性應始終小於定型正確性，過度學習與適當學習其的區別在於正確性的「下降幅度」。 

在 **A** 與 **B** 模型中，**A** 模型是較佳的模型，因為該模型擁有更高的測試正確性，雖然測試正確性為 95% 略低於定型正確性，但這種微小差異並不代表存在著過度學習。 您不會僅因為定型和測試正確性較接近就選擇 **B** 模型。

**C** 模型則明顯為過度學習的案例；其定型正確性非常高，但測試正確性卻沒有那麼高。 這是一項主觀的區別，但其來自對於問題和資料的了解，以及可接受錯誤的程度。

## <a name="prevent-over-fitting"></a>防止過度學習

在最糟糕的情況下，過度學習的模型會假設在定型期間所出現特徵值組合，一律會產生與目標完全相同的輸出。

避免過度學習的最佳方式就是遵循 ML 最佳做法，包括：

* 使用更多定型資料，並消除統計偏差
* 防止目標洩漏
* 使用較少的特徵
* **正規化和超參數最佳化**
* **模型複雜性限制**
* **交叉驗證**

在自動化 ML 中，上述前三個項目是**由您實作的最佳做法**。 後三個粗體顯示項目依預設為**由自動化 ML 實作的最佳做法**，以防止過度學習。 在自動化 ML 以外的設定中，所有六個最佳做法都值得遵循，以避免模型過度學習。

### <a name="best-practices-you-implement"></a>由您實作的最佳做法

使用**更多資料**是避免過度學習的最簡單且最佳方式，且通常還能夠同時提高正確性。 當使用更多資料時，模型會變得更難記住確切的模式，並會迫使模型使用更有彈性的解決方案，以容納更多條件。 也請務必辨識**統計偏差**，以避免定型資料包含不存在於即時預測資料中的偏差模式。 這種情況可能很難解決，因為即使定型和測試集之間不存在過度學習，但與即時預測資料相比時仍可能出現過度學習。

**目標洩漏**是類似的問題，您可能不會在定型/測試集中發現過度學習，而是在預測階段時出現過度學習。 當模型在定型期間存取通常在預測階段不應該擁有的資料而「作弊」時，就會發生目標洩漏。 例如，如果您想要在星期一時預測某項商品在星期五的價格，但其中一項特徵不小心包含了星期四的資料，這就是模型在預測階段不該出現的資料，因為模型並無法透視未來。 目標洩漏是很容易遺漏的錯誤，其特點往往是因為問題具有異常高的正確性。 如果您嘗試預測股票價格，而定型的模型具有 95% 正確性，則特徵中便可能存在目標洩漏。

**移除特徵**也可以讓模型不會使用太多欄位來記住特定模式，藉此避免過度學習，使其更具彈性。 定量測量可能很困難，但如果您可移除特徵並維持相同的正確性，則或許能夠讓模型更具彈性，並降低過度學習的風險。

### <a name="best-practices-automated-ml-implements"></a>由自動化 ML 實作的最佳做法

**正規化**是將成本函式最小化以抑制複雜且過度學習模型的程序。 正規化函式的類型有許多種，但在一般情況下，這類函式會抑制模型的係數大小、變異數和複雜度。 自動化 ML 會以不同的組合使用 L1 (Lasso)、L2 (Ridge) 以及 ElasticNet (同時使用 L1 和 L2) 的不同組合，並搭配不同模型超參數設定來控制過度學習。 簡單來說，自動化 ML 會控制模型受管制的程度，並選擇最佳的結果。

自動化 ML 也會實作明確的**模型複雜性限制**來避免過度學習。 在大部分情況下，此實作專門用於決策樹或樹系演算法，其中個別樹狀結構的最大深度會受到限制，而樹系或整體技術所使用的樹狀結構總數亦會受到限制。

**交叉驗證 (CV)** 是採納完整定型資料中的許多子集，並在個別子集上定型模型的程序。 其概念是，模型可能會「幸運地」在其中一個子集取得絕佳的正確性，但使用許多子集時，模型並不會每次都達到如此高的正確性。 執行 CV 時，您會提供驗證用的鑑效組資料集、指定 CV 摺疊 (子集數目)，然後自動化 ML 將定型模型並微調超參數，以將驗證集的錯誤降至最低。 單一 CV 摺疊可能會出現過度學習，但藉由使用許多摺疊，即可減少最終模型過度學習的機率。 其缺點是，CV 的定型時間較長，因而產生較高的成本，因為模型不會只定型一次，而是針對 *n* 個 CV 子集分別進行一次定型。 

> [!NOTE]
> 交叉驗證並非預設啟用項目；其必須在自動化 ML 設定中進行設定。 不過，在設定交叉驗證並提供驗證資料集之後，便能夠將程序自動化。 深入瞭解[自動 ML 中的交叉驗證](how-to-configure-cross-validation-data-splits.md)設定

<a name="imbalance"></a>

## <a name="identify-models-with-imbalanced-data"></a>識別具有不平衡資料的模型

不平衡資料通常會在機器學習分類案例的資料中被發現，這代表在每個類別中包含不成比例的觀察資料。 不平衡資料可能會造成對模型正確性判斷錯誤，因為輸入的資料偏向同一種類別，導致定型的模型針對該偏差進行模擬。 

此外，自動化 ML 執行會自動產生下列圖表，可協助了解模型分類的正確程度，並識可能受到不平衡資料影響的模型。

圖表| 描述
---|---
[混淆矩陣](how-to-understand-automated-ml.md#confusion-matrix)| 根據資料的實際標籤，評估正確分類的標籤。 
[精確度與重新叫用率](how-to-understand-automated-ml.md#precision-recall-chart)| 根據資料中所找到標籤執行個體的比率，評估正確標籤的比率 
[ROC 曲線](how-to-understand-automated-ml.md#roc)| 根據誤判標籤的比例，評估正確標籤的比率。

## <a name="handle-imbalanced-data"></a>處理不平衡的資料 

**自動化 ML 有內建的功能**，可協助處理不平衡資料（例如，），以簡化機器學習工作流程的目的。 

- **權數資料行**：自動化 ML 支援以權數作為輸入的資料行，讓資料中的資料列進行加權或減少，可用來讓類別變得更多或更少「重要」。

- 當少數類別中的樣本數目等於或少於多數類別中樣本數的20% 時，自動化 ML 會偵測到不平衡的演算法，其中少數類別指的是具有最少樣本的樣本，而多數類別指的是具有大部分樣本的類別。 接著，AutoML 會使用子樣本資料來執行實驗，以檢查使用類別加權是否可解決此問題並改善效能。 如果透過此實驗 ascertains 效能較佳，則會套用此補救措施。

- 使用效能指標來更適當地處理不平衡資料。 例如，AUC_weighted 是一個主要計量，它會根據代表該類別之樣本的相對數目來計算每個類別的比重，因此更適合不平衡。

下列技巧是在 **自動化 ML 以外**處理不平衡資料的其他選項。 

- 重新取樣以平衡類別 (將較少類別向上取樣或將較多類別向下取樣)。 這些方法需要專業知識來處理和分析。

- 檢查不平衡資料的效能計量。 例如，F1 分數是精確度和召回率的調和平均數。 精確度會測量分類器的 exactness，其中較高的精確度表示較少的誤報，而召回量值則是測量分類器的完整性，而較高的召回率表示較少的錯誤。

## <a name="next-steps"></a>後續步驟

查看範例並了解如何使用自動化機器學習來建置模型：

+ 遵循[教學課程：使用 Azure Machine Learning 自動定型迴歸模型](tutorial-auto-train-models.md)

+ 設定自動定型實驗的設定：
  + 在 Azure Machine Learning Studio 中，[使用這些步驟](how-to-use-automated-ml-for-ml-models.md)。
  + 針對 Python SDK，[使用這些步驟](how-to-configure-auto-train.md)。


