---
title: 功能雜湊模組參考
titleSuffix: Azure Machine Learning
description: 瞭解如何在 Azure 機器學習中使用功能雜湊模組來處理文本資料。
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: reference
author: likebupt
ms.author: keli19
ms.date: 02/22/2020
ms.openlocfilehash: 7178417a5c20afe5b1ed02bc526ec174704962df
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 03/28/2020
ms.locfileid: "79456245"
---
# <a name="feature-hashing-module-reference"></a>功能雜湊模組參考

本文介紹 Azure 機器學習設計器（預覽）中包含的模組。

使用"功能雜湊"模組將英語文本流轉換為一組整數要素。 然後，您可以將此雜湊功能集傳遞給機器學習演算法，以訓練文本分析模型。

本模組中提供的功能散列功能基於 nimbusml 框架。 有關詳細資訊，請參閱[NgramHash 類](https://docs.microsoft.com/python/api/nimbusml/nimbusml.feature_extraction.text.extractor.ngramhash?view=nimbusml-py-latest)。

## <a name="what-is-feature-hashing"></a>什麼是功能雜湊？

特徵雜湊的工作原理是將唯一標記轉換為整數。 它對作為輸入提供的確切字串進行操作，不執行任何語言分析或預處理。 

例如，採用一組這樣的簡單句子，然後是情緒評分。 假設您要使用此文本生成模型。

|使用者文本|情感|
|--------------|---------------|
|我喜歡這本書|3|
|我討厭這本書|1|
|這本書很棒|3|
|我喜歡書|2|

在內部，功能雜湊模組創建 n 克字典。 例如，此資料集的 bigrams 清單如下所示：

|術語（大錘子）|頻率|
|------------|---------------|
|這本書|3|
|我愛|1|
|我討厭|1|
|我愛|1|

您可以使用**N-gram**屬性控制 n-gram 的大小。 如果選擇大圖，也會計算單字。 詞典還將包括以下單個術語：

|學期（單克）|頻率|
|------------|---------------|
|預訂|3|
|I|3|
|書籍|1|
|was|1|

生成字典後，特徵雜湊模組將字典術語轉換為雜湊值。 然後，它計算是否在每種情況下都使用了一個要素。 對於每行文本資料，模組輸出一組列，每個雜湊要素輸出一列。

例如，在雜湊後，要素列可能如下所示：

|評等|雜湊特徵 1|雜湊功能 2|雜湊功能 3|
|-----|-----|-----|-----|
|4|1|1|0|
|5|0|0|0|

* 如果列中的值為 0，則該行不包含雜湊特徵。
* 如果值為 1，則該行確實包含該要素。

要素散列允許您將可變長度的文字文件表示為長度相等的數位要素向量，以減少尺寸。 如果您嘗試將文本列用於訓練，則該列將被視為具有許多不同值的分類要素列。

數位輸出還允許使用常見的機器學習方法，包括分類、聚類和資訊檢索。 由於查找操作可以使用整數雜湊而不是字串比較，因此獲取要素權重的速度也更快。

## <a name="configure-the-feature-hashing-module"></a>配置功能雜湊模組

1.  在設計器中將功能雜湊模組添加到管道中。

1. 連接包含要分析的文本的資料集。

    > [!TIP]
    > 由於特徵雜湊不執行詞法操作（如詞幹或截斷），因此在應用特徵雜湊之前，有時可以通過預處理文本獲得更好的結果。 

1. 將**目標列**設置為要轉換為雜湊要素的文本列。 請注意下列事項：

    * 列必須是字串資料類型。
    
    * 選擇多個文本列會對要素維度產生重大影響。 例如，10 位雜湊的列數從單個列的 1，024 到兩列的 2，048。

1. 使用**雜湊位大小**指定創建雜湊表時要使用的位數。
    
    預設位大小為 10。 對於許多問題，此值就足夠了。 您可能需要更多空間以避免碰撞，具體取決於訓練文本中 n-gram 詞彙的大小。
    
1. 對於**N-g，** 輸入一個數位，用於定義要添加到訓練字典的 n-gram 的最大長度。 n-gram 是*n*個單詞序列，被視為唯一單位。

    例如，如果輸入 3，將創建單圖、大圖和三圖。

1. 提交管道。

## <a name="results"></a>結果

處理完成後，模組將輸出轉換後的資料集，其中原始文本列已轉換為多個列。 每清單示文本中的要素。 根據字典的顯著性，生成的資料集可能很大：

|列名稱 1|列類型 2|
|-------------------|-------------------|
|使用者文本|原始資料列|
|情緒|原始資料列|
|USERTEXT - 雜湊功能 1|雜湊特徵列|
|USERTEXT - 雜湊功能 2|雜湊特徵列|
|USERTEXT - 雜湊功能 n|雜湊特徵列|
|USERTEXT - 雜湊功能 1024|雜湊特徵列|

創建轉換後的資料集後，可以將其用作訓練模型模組的輸入。
 
## <a name="best-practices"></a>最佳作法

以下最佳實踐可以説明您充分利用功能雜湊模組：

* 在使用功能雜湊之前添加預處理文本模組以預處理輸入文本。 

* 在功能雜湊模組之後添加"選擇列"模組，從輸出資料集中刪除文本列。 生成雜湊特徵後，不需要文本列。
    
* 請考慮使用這些文本預處理選項，以簡化結果並提高準確性：

    * 斷字
    * 停止刪除單詞
    * 案例正常化
    * 刪除標點符號和特殊字元
    * 詞幹分析  

應用於任何解決方案的最佳預處理方法集取決於域、詞彙量和業務需求。 使用資料管道查看哪些文本處理方法最為有效。

## <a name="next-steps"></a>後續步驟
            
查看[Azure 機器學習可用的模組集](module-reference.md) 
